{"cells":[{"cell_type":"code","source":["print(\"PROGRAM DIMULAI\")\n","\n","import pandas as pd\n","import re, string\n","from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.util import ngrams\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import LatentDirichletAllocation\n","\n","nltk.download('stopwords')\n","\n","# ==================== LOAD DATA ====================\n","\n","print(\"MEMUAT DATA...\")\n","\n","grab = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\grab_2500.csv.csv\")\n","gojek = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\gojek_2500.csv.csv\")\n","\n","grab = grab[[\"Ulasan\"]].rename(columns={\"Ulasan\": \"text\"})\n","gojek = gojek[[\"content\"]].rename(columns={\"content\": \"text\"})\n","\n","grab = grab.reset_index(drop=True)\n","gojek = gojek.reset_index(drop=True)\n","\n","grab[\"text\"] = grab[\"text\"].astype(str).str.slice(0, 500)\n","gojek[\"text\"] = gojek[\"text\"].astype(str).str.slice(0, 500)\n","\n","# ==================== PREPROCESS ====================\n","\n","print(\"PREPROCESSING...\")\n","\n","stop_words = set(stopwords.words('indonesian'))\n","stemmer = StemmerFactory().create_stemmer()\n","\n","normalisasi = {\n","    \"gk\":\"tidak\",\"ga\":\"tidak\",\"nggak\":\"tidak\",\n","    \"bgt\":\"banget\",\"bgtt\":\"banget\",\"mantul\":\"mantap\",\"asikkk\":\"asik\"\n","}\n","\n","def clean_text(text):\n","    try:\n","        text = text.lower()\n","        text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n","        text = re.sub(r'\\d+', ' ', text)\n","        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n","        text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","        hasil = []\n","        for kata in text.split():\n","            kata = normalisasi.get(kata, kata)\n","            if kata not in stop_words and len(kata) > 3:\n","                hasil.append(stemmer.stem(kata))\n","        return \" \".join(hasil)\n","    except:\n","        return \"\"\n","\n","print(\"PREPROCESSING GRAB...\")\n","grab_clean = []\n","for i in range(len(grab)):\n","    grab_clean.append(clean_text(grab.loc[i, \"text\"]))\n","    if i % 200 == 0: print(\"Grab:\", i)\n","grab[\"clean\"] = grab_clean\n","\n","print(\"PREPROCESSING GOJEK...\")\n","gojek_clean = []\n","for i in range(len(gojek)):\n","    gojek_clean.append(clean_text(gojek.loc[i, \"text\"]))\n","    if i % 200 == 0: print(\"Gojek:\", i)\n","gojek[\"clean\"] = gojek_clean\n","\n","# ==================== SENTIMENT ====================\n","\n","positif = [\"bagus\",\"mantap\",\"cepat\",\"ramah\",\"puas\",\"baik\"]\n","negatif = [\"jelek\",\"lama\",\"buruk\",\"kecewa\",\"mahal\",\"batal\"]\n","\n","def label_sentimen(text):\n","    skor = 0\n","    for p in positif:\n","        if p in text: skor += 1\n","    for n in negatif:\n","        if n in text: skor -= 1\n","    if skor > 0: return \"Positif\"\n","    if skor < 0: return \"Negatif\"\n","    return \"Netral\"\n","\n","grab[\"sentimen\"] = grab[\"clean\"].apply(label_sentimen)\n","gojek[\"sentimen\"] = gojek[\"clean\"].apply(label_sentimen)\n","\n","# ==================== WORDCLOUD ====================\n","\n","def show_wordcloud(data, title):\n","    wc = WordCloud(width=800,height=400,background_color=\"white\").generate(\" \".join(data))\n","    plt.figure(figsize=(10,5))\n","    plt.imshow(wc)\n","    plt.axis(\"off\")\n","    plt.title(title)\n","    plt.show()\n","\n","show_wordcloud(grab[\"clean\"], \"WordCloud Grab\")\n","show_wordcloud(gojek[\"clean\"], \"WordCloud Gojek\")\n","\n","# ==================== N-GRAM ====================\n","\n","def plot_ngram(data, title):\n","    tokens = \" \".join(data).split()\n","    top_ngrams = Counter(ngrams(tokens, 4)).most_common(10)\n","\n","    labels = [\" \".join(k) for k,v in top_ngrams]\n","    values = [v for k,v in top_ngrams]\n","\n","    plt.figure(figsize=(10,5))\n","    plt.bar(labels, values)\n","    plt.xticks(rotation=75)\n","    plt.title(title)\n","    plt.show()\n","\n","plot_ngram(grab[\"clean\"], \"Top 10 4-Gram Grab\")\n","plot_ngram(gojek[\"clean\"], \"Top 10 4-Gram Gojek\")\n","\n","# ==================== CLUSTERING ====================\n","\n","vectorizer = TfidfVectorizer(max_features=3000)\n","X_grab = vectorizer.fit_transform(grab[\"clean\"])\n","X_gojek = vectorizer.fit_transform(gojek[\"clean\"])\n","\n","kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n","\n","grab[\"cluster\"] = kmeans.fit_predict(X_grab)\n","gojek[\"cluster\"] = kmeans.fit_predict(X_gojek)\n","\n","print(\"\\nDistribusi Cluster Grab:\")\n","print(grab[\"cluster\"].value_counts())\n","\n","print(\"\\nDistribusi Cluster Gojek:\")\n","print(gojek[\"cluster\"].value_counts())\n","\n","# ==================== TOPIC MODELING ====================\n","\n","lda = LatentDirichletAllocation(n_components=3, random_state=42)\n","\n","lda.fit(X_grab)\n","feature_names = vectorizer.get_feature_names_out()\n","\n","def show_topics(model, feature_names, n_words=8):\n","    for i, topic in enumerate(model.components_):\n","        print(f\"\\nTopik {i+1}:\")\n","        print(\", \".join([feature_names[j] for j in topic.argsort()[-n_words:]]))\n","\n","print(\"\\nTopik Grab:\")\n","show_topics(lda, feature_names)\n","\n","# ==================== VISUAL SENTIMEN ====================\n","\n","def plot_sentiment(df, title):\n","    count = df[\"sentimen\"].value_counts()\n","    plt.figure(figsize=(6,4))\n","    plt.bar(count.index, count.values)\n","    plt.title(title)\n","    plt.ylabel(\"Jumlah Data\")\n","    plt.show()\n","\n","plot_sentiment(grab, \"Distribusi Sentimen Grab\")\n","plot_sentiment(gojek, \"Distribusi Sentimen Gojek\")\n","\n","# ==================== SAVE FILE ====================\n","\n","grab.to_csv(r\"C:\\Users\\Dell\\Downloads\\grab_final.csv\", index=False)\n","gojek.to_csv(r\"C:\\Users\\Dell\\Downloads\\gojek_final.csv\", index=False)\n","\n","print(\"\\nSELESAI TOTAL â€” FILE TERSIMPAN\")\n"],"metadata":{"id":"6AB65P8vrNfq","executionInfo":{"status":"error","timestamp":1768447498487,"user_tz":-420,"elapsed":63,"user":{"displayName":"","userId":""}},"outputId":"a3768c37-f801-49c8-981a-1d0e3eb5be26","colab":{"base_uri":"https://localhost:8080/","height":401}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PROGRAM DIMULAI\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'Sastrawi'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3390932633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSastrawi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStemmerFactory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStemmerFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Sastrawi'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}],"metadata":{"colab":{"toc_visible":true,"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1768447507409}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}